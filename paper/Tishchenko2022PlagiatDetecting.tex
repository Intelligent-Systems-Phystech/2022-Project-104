\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\usepackage[]{algorithmic}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subfig}
\newcommand{\hdir}{.}
\newtheorem{statement}{Утверждение}

\begin{document}

\title
    []
    {Кроссязычный поиск дубликатов с использованием тематического моделирования}

\author
    [Е.\,В.~Тищенко]
    {Е.\,В.~Тищенко, К.\,В.~Воронцов}
    [Е.\,В.~Тищенко$^1$, К.\,В.~Воронцов$^2$, П.\,С.~Потапова$^3$]

\abstract{
В статье рассматривается задача кроссязычного поиска текстового плагиата. Целью работы является получение модели, выделяющей информацию о распределении слов в тексте независимо от их языковой принадлежности, при этом ограниченной по размеру и времени обучения для ее практического использования.

\textbf{Ключевые слова}: \emph{машинное обучение, тематическое моделирование, мультиязыковой поиск дубликатов, обработка текстов на естественном языке, мультиязыковая обработка текстов}
}



\maketitle
\linenumbers
\section{Введение}

Задача поиска и распознавания плагиата является важной из-за невозможности проверить все документы общей тематики на плагиат в силу размеров глобальной сети. Задача становится особенно трудной, так как возникает множество документов, являющихся переводом исходных работ. Согласно исследованиям Donald L. McCabe,\cite{donaldSurvey}  $ 36\% $ студентов американских университетов перефразировали или копировали информацию из всемирной паутины без ссылки на источник. 

Методы векторизации документов для поиска плагиата  \cite{methodMLPlag, regression} преимущественно ограничиваются одним языком. В таком случае возникает проблема создания единообразной системы получения векторных представлений мультиязыковой коллекции документов. Для возможности применения модели за пределами научных экспериментов ставятся технические ограничения ресурсами сервера, а именно на размер модели, временную сложность обучения.

Объектом исследования являются мультиязыковые тематические модели, алгоритмы поиска документов в текстовой коллекции по словам и документам, способы векторного представления слов и документов запроса и коллекции, применяемые для поиска дубликатов независимо от языковой принадлежности.

Тематическая модель коллекции текстовых документов определяет, к каким темам относится каждый документ и какие слова или термины образуют каждую тему. Вероятностная тематическая модель описывает каждую тему дискретным распределением вероятностей слов, а каждый документ $\--$ дискретным распределением вероятностей тем. Тематическая модель преобразует любой текст в вектор вероятностей тем. 

Для решения задачи используется мультимодальная тематическая модель. Такая тематическая модель описывает документы, содержащие метаданные наряду с основым текстом. Метаданные улучшают точность определения тематики документа. В качестве модальностей используются 100 языков, а также научные рубрики. Использование языков в качестве модальностей позволяет получить векторное представление текста, независимое от оригинального языка текста, что позволяет решать проблему поиска плагиата без ограничения на язык статьи. Во время предобработки текста используется BPE токенизация $\--$ итеративная замена наиболее встречаемой пары символов на символ, который не встречается в слове. Это существенно уменьшает объем изначального словаря для практического применения модели.

Целью эксперимента является построение модели, исследование влияния регуляризации и предобработки текстовых данных на качество поиска, подбор разнообразных функций для сравнения тематических расстояних векторов а также поиск эвристик для улучшения точности предсказаний модели. В качестве обучающих данных используются статьи с сайта Wikipedia, а также выборка научных статей из научной электронной библиотеки eLIBRARY.ru.

\section{Постановка задачи поиска дубликатов документов}

Пусть $D~-$ некоторая коллекция документов, $T~-$ множество тем документов. Кандидатом на дубликат  для документа $d \in D$ обозначим такой элемент коллекции $f(d)$, что  $$f(d) = \argmin_{d' \in D \setminus \{d\}} distance(m(d), m(d'))$$ 
В качестве функции $distance$ может быть использована произвольная метрика векторного пространства. Функция  $m(d) \--$ модель, осуществляющая преобразование документа в векторное пространство. Качество модели поиска дубликатов измеряется на тестовой выборке при помощи двух метрик сопоставления документов:

1. Средняя частота, с которой документ-запрос попадает в топ 10\%.  Для документа в тестовой выборке уже известно, какие документы являются переводом исходного. Рассматривается доля тех документов, для которых среди 10\% отранжированных кандидатов на дубликат встречаются их переводы. 

2. Средний процент документов в топ 10\% документов-переводов, которые имеют такую же рубрику, что у документа-запроса. Аналогично предыдущей метрике, однако рассматриваются не все документы в коллекции, а лишь определенной рубрики.

Требуется решить задачу поиска дубликатов, при этом качество должно превосходить 0.9 по первой метрке, 0.3 по второй. Также необходимо ограничить размер модели до 100 Гб, а обучение модели должно производиться не более чем за 24 часа.

В качестве преобразования текства в векторном представлении используется тематическое моделирование. Тематическая модель \cite{basetematic}  по коллекции документов строит вероятностное распределение $p(w|t)$ термов w $-$ слов, словосочетаний и терминов в темах $t \in T$. Согласно гипотезе об условной независимости, а также формуле полной вероятности, распределение термов w в документе d является вероятностной смесью распределений термов в темах $\phi_{wt} = p(w|t)$ с весами $\theta_{td}=p(t|d)$ $$p(w|d) = \sum_{t \in T} p(w|t, d)p(t|d) = \sum_{t \in T} p(w|t)p(t|d) =\sum_{t\in T}\phi_{wt}\theta_{td}$$
Данное выражение можно переписать в матричном виде. Матрица частот термов в документах $F \approx \Phi \Theta$. Так как число тем, как правило, намного больше, чем число документов, то требуется найти такое разложение, ранг которого не превосходит $|T|$.


\section{Вычислительный эксперимент}

В рамках эксперимента ставится задача поиска оптимальных параметров тематической модели, а также метода токенизации текста, при которых будут достигнуты требования. После выбора оптимальных параметров будет проведено исследование, как именно влияет отдельный параметр на качество модели.

\subsection{Данные}

В качестве данных для обучения тематической модели использовались статьи научной электронной библиотеки eLibrary\footnote{elibrary.ru}, а также статьи многоязычной интернет-энциклопедия Wikipedia\footnote{wikipedia.org}, описанные в работе \cite{}.
Для подавляющего числа научных статей eLibrary были известны рубрики Государственного рубрикатора научно-технической информаци (ГРНТИ)\footnote{grnti.ru} и Универсального десятичного классификатора (УДК)\footnote{udcsummary.info}. Формирование выборки статьей на 100 языках происходило следующим образом. Было отобрано 24 тысячи статей библиотеки eLibrary на русском и английском языках. Затем статьи были переведены на 42 языка. Языки были выбраны по причине их большой представленности среди научных текстов. Перевод осуществлялся при помощи системы статистического машинного перевода Moses \cite{Moses}. Также для всех языков, включая эти 42, были собраны статьи из энциклопедии Wikipedia.

\subsection{Базовые модели}

В качестве базовой модели используется тематическая модель, испльзующая в качестве модальностей 100 языков. Обучение происходит на основе данных Википедии. Используются тексты, посвященные 300 различным темам. При предобработке текста используется метод BPE токенизации, причем изначальный объем словаря в 120 тысяч токенов ужат до 2 тысяч для каждого отдельного языка. Обучение модели занимает порядка 6 часов, а размер модели составляет 4.6 Гб. Тесты качества модели описаны ниже.

\begin{table}[htb]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\begin{tabular}[c]{@{}l@{}}Средняя \\ частота\\ УДК\end{tabular} & \begin{tabular}[c]{@{}l@{}}Средний \\ процент\\ УДК\end{tabular} & \begin{tabular}[c]{@{}l@{}}Средняя \\ частота\\ ГРНТИ\end{tabular} & \begin{tabular}[c]{@{}l@{}}Средний\\ процент\\ ГРНТИ\end{tabular} \\ \hline
0.4332                                                           & Coming soon                                                      & Coming soon                                                        & Coming soon                                                       \\ \hline
\end{tabular}
\end{table}

\subsection{Модель}

% предобработка данных

% 1. БРЕ токенизация

% 2. исключили

\subsection{Результаты}

\subsection{Абляционные эксперименты}

\begin{thebibliography}{4}

\bibitem{donaldSurvey}
    \BibAuthor{Donald L. McCabe}
    Cheating among college and university students: A North American perspective//
    \BibJournal{International Journal for Educational Integrity}, 2005
    
\bibitem{methodMLPlag}
    \BibAuthor{Zdenek Ceska, Michal Toman, and Karel Jezek}
    Multilingual Plagiarism Detection//
    \BibJournal{Artificial Intelligence: Methodology, Systems and Applications}, 2008
    
\bibitem{regression}
    \BibAuthor{Duygu Ataman, Jose G. C. de Souza, Marco Turchi, Matteo Negri}
    Cross-lingual Semantic Similarity Measurement Using Quality Estimation Features and Compositional Bilingual Word Embeddings//
    
\bibitem{basetematic}
    \BibAuthor{Воронцов К. В.}
    Обзор вероятностных тематических моделей.//
  
\bibitem{Moses}
  \textit{Koehn P. et al.} Moses: Open source toolkit for statistical machine translation //Proceedings of the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions. – 2007. – С. 177-180.

	  
\end{thebibliography}

\end{document}